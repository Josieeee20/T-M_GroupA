{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78eced2d-626a-4ae2-92d9-6bc835b28d55",
   "metadata": {},
   "source": [
    "## Prepare Nodes File: Topic Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbaaff9b-fb80-4090-8c99-e580c68256db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "738ac5f5-dbec-4d34-99f0-951e80f38506",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/First_Step/Prepare_Corpus/combine_president_speeches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05931fad-f853-4314-bbbc-b55d683e5aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1037, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d64d3ec-b2ea-429f-ab32-9b26d91bbb9c",
   "metadata": {},
   "source": [
    "### Creating a file formatting for topic analysis (index\\t label\\t text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dde5d4dd-570c-46fb-935f-2a2ae420dc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the transcript files\n",
    "transcript_directory = 'corpus'\n",
    "\n",
    "# Get a list of all transcript file paths\n",
    "transcript_files = [file for file in os.listdir(transcript_directory) if file.endswith('.txt')]\n",
    "\n",
    "# Sort the transcript files in ascending order\n",
    "transcript_files.sort()\n",
    "\n",
    "# Open the output file to write the concatenated transcripts\n",
    "output_file_path = 'concatenated_transcripts.txt'\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    for index, transcript_file in enumerate(transcript_files, start=1):\n",
    "        transcript_file_path = os.path.join(transcript_directory, transcript_file)\n",
    "        \n",
    "        # Read the contents of the current transcript file\n",
    "        with open(transcript_file_path, 'r') as file:\n",
    "            transcript = file.read().strip()\n",
    "        \n",
    "        # Format and write the transcript to the output file\n",
    "        output_file.write(f'{index}\\t{transcript_file[:-4]}\\t{transcript}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf75a1b-2686-47af-840b-7a873e73a347",
   "metadata": {},
   "source": [
    "### Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fe2b792f-5bef-4d85-8d95-1f94c623f5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tomotopy in /Users/chengluotong/anaconda3/lib/python3.11/site-packages (0.12.5)\n",
      "Requirement already satisfied: little_mallet_wrapper in /Users/chengluotong/anaconda3/lib/python3.11/site-packages (0.5.0)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /Users/chengluotong/anaconda3/lib/python3.11/site-packages (from tomotopy) (1.26.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tomotopy little_mallet_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "911d3082-52bf-4e16-85cd-bab3f33ccfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomotopy as tp\n",
    "import little_mallet_wrapper\n",
    "import seaborn\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def make_md(string):\n",
    "    display(Markdown(str(string)))\n",
    "\n",
    "def get_top_docs(docs, labels, ids, topic_distributions, topic_index, n=5):    \n",
    "    sorted_data = sorted([(distribution[topic_index], document, label, docid) \n",
    "                          for distribution, document, label, docid\n",
    "                          in zip(topic_distributions, docs, labels, ids)], reverse=True)\n",
    "    topic_words = topics[topic_index]\n",
    "    make_md(f\"### ✨Topic {topic_index}✨\\n\\n{topic_words}\\n\\n---\")\n",
    "    for probability, doc, label, docid in sorted_data[:n]:\n",
    "        # Make topic words bolded\n",
    "        for word in topic_words.split():\n",
    "            if word in doc.lower():\n",
    "                doc = re.sub(f\"\\\\b{word}\\\\b\", f\"**{word}**\", doc, re.IGNORECASE)\n",
    "        if len(doc) > 1000:\n",
    "            doc = doc[:1000] + ' [...]'\n",
    "        make_md(f'✨  \\n**Topic Probability**: {probability:.3f}  **Label**: {label}  **ID**: {docid}\\n\\n**Document**: {doc}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2337ab6c-b581-47d5-9974-9ff373582b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents: 45\n",
      "Mean Number of Words per Document: 31002.2\n",
      "Vocabulary Size: 36582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(45, 45, 45)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetfile = 'concatenated_transcripts.txt'\n",
    "\n",
    "# To use a different stop words list, enable the following lines\n",
    "# and the line with \"stop_words\" below:\n",
    "stopwordsfile = 'english.txt'\n",
    "with open(stopwordsfile) as inp:\n",
    "    stop_words = inp.read().splitlines()\n",
    "\n",
    "with open(datasetfile) as inp:\n",
    "    lines = inp.read().splitlines()\n",
    "\n",
    "    training_data = []\n",
    "original_texts = []\n",
    "labels = []\n",
    "ids = []\n",
    "for line in lines:\n",
    "    try:\n",
    "        docid, label, text = line.strip().split('\\t', 2)\n",
    "    except ValueError:\n",
    "        continue\n",
    "    processed_text = little_mallet_wrapper.process_string(\n",
    "            text, numbers='remove',\n",
    "             stop_words=stop_words,\n",
    "            stop_words_extra=[])\n",
    "    if not processed_text.strip():  # skip empty documents\n",
    "        continue\n",
    "    training_data.append(processed_text)\n",
    "    original_texts.append(text)\n",
    "    labels.append(label)\n",
    "    ids.append(docid)\n",
    "\n",
    "little_mallet_wrapper.print_dataset_stats(training_data)\n",
    "len(training_data), len(original_texts), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1bd2a806-7eee-4479-8225-ee3775455b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic Model Training...\n",
      "\n",
      "\n",
      "Iteration: 0\tLog-likelihood: -8.789014255449597\n",
      "Iteration: 50\tLog-likelihood: -8.813848984721211\n",
      "Iteration: 100\tLog-likelihood: -8.827444014806794\n",
      "Iteration: 150\tLog-likelihood: -8.840465850804966\n",
      "Iteration: 200\tLog-likelihood: -8.849922585769074\n",
      "Iteration: 250\tLog-likelihood: -8.854753045187387\n",
      "Iteration: 300\tLog-likelihood: -8.854315346654339\n",
      "Iteration: 350\tLog-likelihood: -8.853892841606706\n",
      "Iteration: 400\tLog-likelihood: -8.85204391833923\n",
      "Iteration: 450\tLog-likelihood: -8.852327837005355\n",
      "Iteration: 500\tLog-likelihood: -8.851268125977999\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "# Number of topics to return\n",
    "num_topics = 7\n",
    "# Number of training iterations\n",
    "iterations = 500\n",
    "\n",
    "# Intialize the model\n",
    "model = tp.LDAModel(k=num_topics)\n",
    "\n",
    "# Add each document to the model, after splitting it up into words\n",
    "for text in training_data:\n",
    "    model.add_doc(text.strip().split())\n",
    "    \n",
    "print(\"Topic Model Training...\\n\\n\")\n",
    "for i in range(0, iterations + 1, 50):\n",
    "    model.train(iterations)\n",
    "    print(f'Iteration: {i}\\tLog-likelihood: {model.ll_per_word}')\n",
    "model.save('topicmodel.bin')\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "113e70e9-8934-4da4-9878-ef86e2909eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tp.LDAModel.load('topicmodel.bin')\n",
    "topic_distributions = [list(doc.get_topic_dist()) for doc in model.docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "406317b4-1570-4fee-a1f9-fddee0ac290b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic Model Results:\n",
      "\n",
      "✨Topic 0✨  president peace people united war nations nation american time freedom country hope congress day program vietnam forces south military defense policy history government america administration days strength americans progress life economic countries national seek continue security house action europe months land north secretary meet asia\n",
      "✨Topic 1✨  united government public congress country citizens power war powers time subject treaty laws duties peace mexico treasury people duty nations force foreign character revenue commerce executive period session consideration nation rights governments debt measures policy territory proper bank attention received british national protection condition relations\n",
      "✨Topic 2✨  constitution people president government congress union question power law authority time principle federal war territory slavery country constitutional military south political north civil rights liberty laws day united passed senate control called majority true persons property national territories office purpose washington subject life held slave\n",
      "✨Topic 3✨  people america american americans government tax security children future time economy congress change energy economic jobs tonight nuclear health care plan percent country freedom education governor families support century community budget soviet weapons union cut middle nation growth opportunity federal human spending family pay responsibility\n",
      "✨Topic 4✨  people president america country american lot united time americans iraq applause nation day job workers jobs law countries love afghanistan china companies coming laughter god money health women military lives millions citizens democrats care history days terrorists democracy border businesses protect deal life stand happen\n",
      "✨Topic 5✨  united government congress law department service legislation secretary report american commission increase attention officers foreign trade fiscal time gold people subject laws cent tariff silver special country relations june consideration countries office total bonds commercial treaty treasury cuba lands day district recommend increased secure civil\n",
      "✨Topic 6✨  government business american national people country public nation action federal war law life labor conditions service power industry panama industrial republic international purpose control private commission justice development washington individual policy time legislation court commerce congress production nations army set hand agriculture future ships navy\n"
     ]
    }
   ],
   "source": [
    "# Numer of topic words to print out\n",
    "num_topic_words = 45\n",
    "\n",
    "print(\"Topic Model Results:\\n\")\n",
    "# Print out top 10 words for each topic\n",
    "topics = []\n",
    "topic_individual_words = []\n",
    "for topic_number in range(0, num_topics):\n",
    "    topic_words = ' '.join(word for word, prob in model.get_topic_words(topic_id=topic_number, top_n=num_topic_words))\n",
    "    topics.append(topic_words)\n",
    "    topic_individual_words.append(topic_words.split())\n",
    "    print(f\"✨Topic {topic_number}✨  {topic_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6461ccd8-acac-4591-8c74-3c0c322b2b6d",
   "metadata": {},
   "source": [
    "### Creating the nodes file with topic probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5e627994-e03b-4896-b441-5b89304b62c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t0: president peace people united</th>\n",
       "      <th>t1: united government public congress</th>\n",
       "      <th>t2: constitution people president government</th>\n",
       "      <th>t3: people america american americans</th>\n",
       "      <th>t4: people president america country</th>\n",
       "      <th>t5: united government congress law</th>\n",
       "      <th>t6: government business american national</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abraham Lincoln</th>\n",
       "      <td>0.052020</td>\n",
       "      <td>0.262301</td>\n",
       "      <td>0.578762</td>\n",
       "      <td>0.009129</td>\n",
       "      <td>0.006417</td>\n",
       "      <td>0.063305</td>\n",
       "      <td>0.028067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andrew Jackson</th>\n",
       "      <td>0.007062</td>\n",
       "      <td>0.695537</td>\n",
       "      <td>0.198855</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.072337</td>\n",
       "      <td>0.023794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andrew Johnson</th>\n",
       "      <td>0.013178</td>\n",
       "      <td>0.388892</td>\n",
       "      <td>0.430575</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.146191</td>\n",
       "      <td>0.021118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barack Obama</th>\n",
       "      <td>0.128714</td>\n",
       "      <td>0.011916</td>\n",
       "      <td>0.029428</td>\n",
       "      <td>0.461172</td>\n",
       "      <td>0.325168</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>0.040099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Benjamin Harrison</th>\n",
       "      <td>0.024009</td>\n",
       "      <td>0.234892</td>\n",
       "      <td>0.074279</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.552868</td>\n",
       "      <td>0.110532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   t0: president peace people united  \\\n",
       "Abraham Lincoln                             0.052020   \n",
       "Andrew Jackson                              0.007062   \n",
       "Andrew Johnson                              0.013178   \n",
       "Barack Obama                                0.128714   \n",
       "Benjamin Harrison                           0.024009   \n",
       "\n",
       "                   t1: united government public congress  \\\n",
       "Abraham Lincoln                                 0.262301   \n",
       "Andrew Jackson                                  0.695537   \n",
       "Andrew Johnson                                  0.388892   \n",
       "Barack Obama                                    0.011916   \n",
       "Benjamin Harrison                               0.234892   \n",
       "\n",
       "                   t2: constitution people president government  \\\n",
       "Abraham Lincoln                                        0.578762   \n",
       "Andrew Jackson                                         0.198855   \n",
       "Andrew Johnson                                         0.430575   \n",
       "Barack Obama                                           0.029428   \n",
       "Benjamin Harrison                                      0.074279   \n",
       "\n",
       "                   t3: people america american americans  \\\n",
       "Abraham Lincoln                                 0.009129   \n",
       "Andrew Jackson                                  0.002098   \n",
       "Andrew Johnson                                  0.000010   \n",
       "Barack Obama                                    0.461172   \n",
       "Benjamin Harrison                               0.002578   \n",
       "\n",
       "                   t4: people president america country  \\\n",
       "Abraham Lincoln                                0.006417   \n",
       "Andrew Jackson                                 0.000319   \n",
       "Andrew Johnson                                 0.000036   \n",
       "Barack Obama                                   0.325168   \n",
       "Benjamin Harrison                              0.000841   \n",
       "\n",
       "                   t5: united government congress law  \\\n",
       "Abraham Lincoln                              0.063305   \n",
       "Andrew Jackson                               0.072337   \n",
       "Andrew Johnson                               0.146191   \n",
       "Barack Obama                                 0.003503   \n",
       "Benjamin Harrison                            0.552868   \n",
       "\n",
       "                   t6: government business american national  \n",
       "Abraham Lincoln                                     0.028067  \n",
       "Andrew Jackson                                      0.023794  \n",
       "Andrew Johnson                                      0.021118  \n",
       "Barack Obama                                        0.040099  \n",
       "Benjamin Harrison                                   0.110532  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put the topic weights into a DataFrame\n",
    "# Columns are topics, rows are documents, each value is a topic weight.\n",
    "columns = ['t%d: %s' % (topic_number,\n",
    "        ' '.join(word for word, _prob in model.get_topic_words(topic_id=topic_number, top_n=4)))\n",
    "    for topic_number in range(model.k)]\n",
    "df = pd.DataFrame([doc.get_topic_dist() for doc in model.docs],\n",
    "             index=labels,\n",
    "             columns=columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "57e22cc4-c805-443c-90d2-9bea4e2552db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename_axis('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e42050ea-4c39-40dd-9c95-ef61bdfd42d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('topic_probability.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9c3e49-0c57-43fd-a426-e8294797c223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
